{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression\n",
    "===========================\n",
    "\n",
    "Multiple linear regression is among the most used statistical data analysis techniques. These models obtain an additive function relating a target variable to a set of predictor variables. This additive function is a sum of terms of the form $\\beta_i \\times X_i$, where $X_i$ is a predictor variable and $\\beta_i$ is a number.\n",
    "\n",
    "There is no predefined way of handling missing values for this type of modeling technique.\n",
    "\n",
    "How to obtain a linear regression model for predicting the frequency of one of the algae.\n",
    "\n",
    "```\n",
    "> lm.a1 <- lm(a1 ~., data = clean.algae[,1:12])\n",
    "```\n",
    "\n",
    "The application of the function *summary()* to a linear model gives some diagnostic information concerning the obtained model. \n",
    "\n",
    "- Information concerning the residuals (i.e., the errors) of the fit of the linear model to the used data. The residuals should have a mean zero and should have a normal distribution (and obviously be as small as possible!)\n",
    "- For earch coefficient (variable) of the multiple regression equation, R will show its value and also its standard error (an estimate of the variability of these coefficients).\n",
    "- To test this hypothesis that each of them is null, that is, $H0: \\beta_i = 0$. To test this hypothesis, the [_t-test_](http://en.wikipedia.org/wiki/Student%27s_t-test) is used. R will show column $Pr(>|t|)$ associated with each coefficient with the level at which the hypothesis that the coefficient is null is rejected.\n",
    "- $R^2$ coefficients (multiple and adjusted) indicate the degree of fit of the model to the data, that is, the proportion of variance in the data that is explained by the model. Values near 1 are better.\n",
    "- We can test the null hypothesis that there is no dependence of the target variable on any of the explanatory variables, that is, $H0 : \\beta_1 = \\beta_2 = \\dots = \\beta_m = 0 $. The F-statistic can be used for this purpose by comparing it to a critical value. R provide the confidence level at which we are sure to reject this null hypothesis. A p-level of 0.0001 means that we are 99.99% confident that the null hypothesis is not true. If the model fails this test ($p > 0.1$), it makes no sense to look at the _t-tests_ on the individual coefficients.\n",
    "\n",
    "How to calculate $R^2$ (Coefficient of determination)\n",
    "------------------------------------------------------\n",
    "\n",
    "1. [Wikipedia pages of $R^2$](http://en.wikipedia.org/wiki/Coefficient_of_determination)\n",
    "\n",
    "2. Calculation\n",
    "\n",
    "A data set has $n$ values marked $y_1,\\dots,y_n$, each associated with a predicted value $f_1,\\dots,f_n$.\n",
    "\n",
    "If $\\bar y$ is the mean of the observed data:\n",
    "\n",
    "$$\\bar y = \\frac{1}{n}\\sum_{i=1}^{n} y_i$$\n",
    "\n",
    "then the variability of the data set can be measured using three [sum of squares](http://mathworld.wolfram.com/SumofSquaresFunction.html) formulas:\n",
    "\n",
    "* The total sum of squares (proportional to the variance of the data)\n",
    "\n",
    "$$ SS_{tot} = \\sum_i (y_i - \\bar y)^2 $$\n",
    "\n",
    "* The regression sum of squares, also called the explained sum of squares\n",
    "\n",
    "$$ SS_{reg} = \\sum_i (f_i - \\bar y)^2 $$\n",
    "\n",
    "* The sum of squares of residuals, also called the residual sum of squares\n",
    "\n",
    "$$ SS_{res} = \\sum_i (y_i - f_i)^2 $$\n",
    "\n",
    "The most general definition of the coefficient of determination is\n",
    "\n",
    "$$ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P values\n",
    "==========\n",
    "\n",
    "#### 1. Alternative hypothesis vs null hypothesis\n",
    "\n",
    "- A statistical hypothesis refers to a probability distribution that is assumed to govern the observed data. If $X$ is a *random variable* representing the observed data and $H$ is the statistical hypothesis under consideration, then the notion of statistical significance can be naively quantified by the conditional probability $Pr(X|H)$\n",
    "- *null hypothesis* refers to a general statement or default position that there is no relationship between two measued phenomena. Rejecting or disproving the null hypothesis -- and thus concluding that there are grounds for believing that there is a relationship between 2 phenomena\n",
    "- *alternative hypothesis* (*research hypothesis*)\n",
    "\n",
    "#### 2. p-value\n",
    "\n",
    "*p-value* is a function of the observed sample results that is used for testing a statistical hypothesis. It is used in the context of null-hypothesis testing in order to quantify the idea of *statistical significance* of evidence.\n",
    "\n",
    "Null hypothesis testing is a [reductio ad absurdum](http://en.wikipedia.org/wiki/Reductio_ad_absurdum) argument adapted to statistics.\n",
    "\n",
    "Before performing the test\n",
    "- a threshold value is chosen, called the significance level (5% or 1%) and denoted as $\\alpha$.\n",
    "- if the _p-value_ is equal to or smaller than the significance level, it suggests that the observed data are inconsistent with the assumption that the null hypothesis is tru, and thus that hypothesis must be rejected and the alternative hypothesis is accepted as true.\n",
    "\n",
    "The p-value is defined as the probability under the assumption of hypothesis $H$, of obtaining a result equal to or more extreme than what was actually observed.\n",
    "\n",
    "\"More extreme than what was actually observed\" can either mean $\\{X \\geq x\\}$ (right tail event) or $\\{X \\leq x\\}$ (left tail event) or the smaller of $\\{X \\geq x\\}$ and $\\{X \\leq x\\}$ (double tailed event). Thus the p-value is given by\n",
    "\n",
    "- $Pr(X \\geq x|H)$ for right tail event\n",
    "- $Pr(X \\leq x|H)$ for left tail event\n",
    "- 2 min $\\{Pr(X \\leq x|H), Pr(X \\geq x|H)\\}$ for double tail event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward elimination\n",
    "====================\n",
    "\n",
    "    > final.lm <- step(lm.a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "- http://nbviewer.ipython.org/github/mwaskom/Psych216/blob/master/week1_tutorial.ipynb\n",
    "- https://scipy-lectures.github.io/intro/matplotlib/matplotlib.html#plotting-with-default-settings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('data': conda)",
   "language": "python",
   "name": "python38264bitdataconda8f24aee9bcd144c3bfccc6d06198ab22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
