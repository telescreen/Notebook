{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subspace\n",
    "A **subspace** of a vector space is a nonempty subset that satisfies the requirements for a vector space: **Linear combinations stay in the subspace**.\n",
    "\n",
    "(i) If we add any vectors $x$ and $y$ in the subspace, $x+y$ in the _subspace_\n",
    "(ii) If we multiply any vector $x$ in the subspace by any scalar $c$, $cx$ is in the _subspace_\n",
    "\n",
    "**the zero vector will belong to every subspace**\n",
    "\n",
    "The smallest subspace $Z$ contains only one vector, the zero vector. It is a \"zero dimensional space\", containing only the point at the origin. _This is the smallest possible vector space_\n",
    "\n",
    "## The Column Space of A\n",
    "\n",
    "**The column space contains all linear combinations of the columns of A**. It is a subspace of $R^m$\n",
    "\n",
    "The system $Ax = b$ is solvable if and only if the vector $b$ can be expressed as a combination of the columns of $A$. Then $b$ is in the column space.\n",
    "\n",
    "_$Ax = b$ can be solved if and only if $b$ lies in the **plane** that is spanned by the two column vectors.\n",
    "\n",
    "What is important is that this plane is not just a subset of $R^3$ it is a subspace. It is the **column space** of A, consisting of **all combinations of the columns**. It is denoted by $C(A)$\n",
    "\n",
    "## The Nullspace of A\n",
    "\n",
    "** The solutions to $Ax = 0$ form a vector space -- the nullspace of A**\n",
    "\n",
    "The **nullspace** of a matrix consists of all vectors $x$ such that $Ax = 0$. It is denoted by $N(A)$. It is a subspace of $R^n$, just as the column space was a subspace of $R^m$.\n",
    "\n",
    "## 8 rules for scalar multiplication and addition\n",
    "1. $x + y = y + x$\n",
    "2. $x + (y + z) = (x + y) + z$\n",
    "3. There is a unique \"zero vector\" such that $x + 0 = x$ for all $x$.\n",
    "4. For each x there is a unique vector $-x$ that $x + (-x) = 0$.\n",
    "5. $1x = x$\n",
    "6. $(c_1c_2)x = c_1(c_2x)$\n",
    "7. $c(x+y) = cx + cy$\n",
    "8. $(c_1 + c_2)x = c_1x + c_2x$.\n",
    "\n",
    "# Solving $Ax = 0$ and $Ax = b$\n",
    "A rectangular matrix brings new possibilities -- $U$ may not have a full set of pivots. This section goes onward from $U$ to a reduced form $R$ -- **The simplest matrix that elimination can give**\n",
    "\n",
    "For an invertible matrix, the nullspace contains only $x = 0$ (multiply $Ax = 0$ by $A^{-1}$). The column space is the whole space ($Ax = b$ has a solution for every $b$). The new questions appear when the nullspace contains _more than the zero vector_ and/or the column space contains _less than all vectors_:\n",
    "\n",
    "1. Any vector $x_n$ in the nullspace can be added to a particular solution $x_p$. The solutions to all linear equations have this form, $x = x_p + x_n$\n",
    "\n",
    "2. When the column space doesn't contain every $b$ in $R^m$, we need the conditions on $b$ that make $Ax = b$ solvable.\n",
    "\n",
    "\n",
    "For any $m$ by $n$ matrix $A$ there is a permutation $P$, a lower triangular $L$ with unit diagonal, and an $m$ by $n$ echelon matrix $U$, such that $PA = LU$.\n",
    "\n",
    "Divide the second row by its pivot 3, so that **all pivots are 1**. Then use the pivot row to produce **zero above the pivot**. This time we subtract a row from a _higher row_. The final result is the **reduced row echelon form $R$**\n",
    "\n",
    "THe row reduced form of a square invertible matrix is the _identity matrix_.\n",
    "\n",
    "## Pivot variables and free variables\n",
    "\n",
    "Example\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 3 & 3 & 2 \\\\\n",
    "2 & 6 & 9 & 7 \\\\\n",
    "-1 & -3 & 3 & 4 \\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "1 & 3 & 3 & 2 \\\\\n",
    "0 & 0 & 3 & 3 \\\\\n",
    "0 & 0 & 6 & 6 \\\\\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "1 & 3 & 3 & 2 \\\\\n",
    "0 & 0 & 3 & 3 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix} \\rightarrow \n",
    "\\begin{bmatrix}\n",
    "1 & 3 & 0 & -1 \\\\\n",
    "0 & 0 & 1 & 1 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "**Nullspace of R (pivot columns in boldface)**\n",
    "\n",
    "$$\n",
    "Rx = \\begin{bmatrix}\n",
    "1 & 3 & 0 & -1 \\\\\n",
    "0 & 0 & 1 & 1 \\\\\n",
    "0 & 0 & 0 & 0 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "u \\\\ v \\\\ w \\\\ y \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 0 \\\\ 0 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The unknowns $u, v, w, y$ go into two groups. One group contains the **pivot variables** those that correspond to **columns with pivots**. The first and third columns contain the pivots, so $u$ and $w$ are the pivot variables. THe other group is made up of the **free variables**, corresponding to **columns without pivots**. These are the second and fourth columns, so $v$ and $y$ are free variables.\n",
    "\n",
    "To find the most general solution to $Rx = 0$, we may assign arbitrary values to the free variables. Suppose we call these values simply $v$ and $y$. THe pivot variables are completely determined in terms of $v$ and $y$\n",
    "\n",
    "Special solutions:\n",
    "\n",
    "$$\n",
    "x = \\begin{bmatrix} -3v + y \\\\ v \\\\ -y \\\\ y \\end{bmatrix}\n",
    " = v \\begin{bmatrix} -3 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix} + \n",
    " y \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "_All solutions are linear combinations of these two_. THe best way to find all solutions to $Ax = 0$ is from the special solutions:\n",
    "\n",
    "1. After reaching $Rx = 0$, identify the pivot variables and free variables\n",
    "2. Give one free variable the value 1, set the other free variables to 0, and solve $Rx = 0$ for the pivot variables. This $x$ is a special solution.\n",
    "3. Every free variable produces its own \"Special solution\" by step 2. The combinations of special solutions form the nullspace -- all solutions to $Ax = 0$.\n",
    "\n",
    "**If $Ax = 0$ has more unknowns than equation ($n > m$), it has at least one special solution: There are more solutions than the trivial $x = 0$**\n",
    "\n",
    "## Solving $Ax = b, Ux = c$ and $Rx = d$\n",
    "\n",
    "1. Reduce $Ax = b$ to $Ux = c$\n",
    "2. With free variables = 0, find a particular solution to $Ax_p = b$ and $Ux_p = c$\n",
    "3. Find the special solutions to $Ax = 0$ (Or $Ux = 0$ or $Rx = 0$). Each free variable, in turn, is 1. Then $x = x_p + $ (any combination $x_n$ of special solutions).\n",
    "\n",
    "Elimination reveals the pivot variables and free varibables. **If there are $r$ pivots, there are $r$ pivot variables and $n-r$ free variables**. r is the **rank of the matrix**.\n",
    "\n",
    "\n",
    "** Suppose elimination reduces $Ax = b$ to $Ux = c$ and $Rx = d$, with $r$ pivot rows and $r$ pivot columns. The rank of those matrices is $r$. The last $m-r$ rows of $U$ and $R$ are zero, so there is a solution only if the last $m-r$ entries of $c$ and $d$ are also zero**\n",
    "\n",
    "\n",
    "# Linear Independence, Basis, and Dimension\n",
    "\n",
    "_The rank counts the number of genuinely independent rows in the matrix A_.\n",
    "\n",
    "## Linear independence\n",
    "\n",
    "Suppose $c_1v_1 + \\dots + c_kv_k = 0$ only happens when $c_1 = \\dots = c_k = 0$. Then the vectors $v_1,\\dots,v_k$ are **linear independent**. If any $c$'s are nonzero, the $v$'s are **linear dependent**. One vector is a combination of the others.\n",
    "\n",
    "The $r$ non zero rows of an echelon matrix $U$ and a reduced matrix R are linearly independent. So are the $r$ columns that contain pivots.\n",
    "\n",
    "A set of $n$ vectors in $R^m$ must be linearly dependent if $n > m$.\n",
    "\n",
    "**The columns of A are independent exactly when $N(A) = \\{zero vector\\}$ **\n",
    "\n",
    "## Spanning a Subspace\n",
    "\n",
    "If a vector space $V$ consists of all linear combinations of $w_1,\\dots,w_l$, then these vectors **span** the space. Every vector $v$ in $V$ is some combination of the $w$7s:\n",
    "\n",
    "Every $v$ comes from $w$'s $v = c_1w_1 + \\dots + c_lw_l$ for some coefficients $c_i$.\n",
    "\n",
    "## Basis for a Vector Space\n",
    "\n",
    "A **basis** for $V$ is a sequence of vectors having two properties at once:\n",
    "1. The vectors are linearly independent\n",
    "2. They span the space $V$\n",
    "\n",
    "**There is one and only one way to write v as a combination of the basis vectors**.\n",
    "\n",
    "The columns of any matrix span its column space. If they are independent, they are a basis for the column space.\n",
    "\n",
    "## Dimension of a Vector Space\n",
    "\n",
    "Any two bases for a vector space $V$ contain the same number of vectors. This number, which is shared by all bases and expresses the number of \"degrees of freedom\" of the space, is the **dimension of V**.\n",
    "\n",
    "# The Four Fundamental Subspaces\n",
    "\n",
    "When the rank is as large as possible, $r = n$ or $r = m$ or $r = m = n$, the matrix has a **left-inverse** B or a **right-inverse** C or a **two-sided** $A^{-1}$.\n",
    "\n",
    "1. The **column space** of $A$ is denoted by $C(A)$. Its dimension is the rank $r$.\n",
    "2. The **nullspace** of $A$ is denoted by $N(A)$. Its dimension is $n-r$.\n",
    "3. The **row space** of A is the column space of $A^T$. It is $C(A^T)$, and it is spanned by the rows of A. Its dimension is also r.\n",
    "4. The **left nullspace** of A is the nullspace of $A^T$. It contains all vectors y such that $A^Ty = 0$, and it is written $N(A^T)$\n",
    "\n",
    "The nullspace $N(A)$ and row space $C(A^T)$ are subspaces of $R^n$\n",
    "The left nullspace $N(A^T)$ and column space $C(A)$ are subspaces of $R^m$.\n",
    "\n",
    "The nullspace is also called the _kernel_ of A\n",
    "\n",
    "\n",
    "# Linear Transformations\n",
    "\n",
    "4 transformations that come from matrices:\n",
    "\n",
    "1. Stretch\n",
    "\n",
    "$A = \\begin{bmatrix} c & 0 \\\\ 0 & c \\end{bmatrix}$\n",
    "\n",
    "A multiple of the indentity matrix, $A = cI$, stretches every vector by the same factor c.\n",
    "\n",
    "2. Rotation\n",
    "\n",
    "$A = \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}$\n",
    "\n",
    "A **rotation** matrix turn the whole space around the origin.\n",
    "\n",
    "3. Reflection\n",
    "\n",
    "$A = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}$\n",
    "\n",
    "Transform every vector into its image on the opposite side of a mirror. The mirror is the $45^0$ line $y = x$\n",
    "\n",
    "4. Projection\n",
    "\n",
    "$A = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}$\n",
    "\n",
    "Take the whole sspace onto a lower dimenstion subspace.\n",
    "\n",
    "Some rules of transformations:\n",
    "* It is impossible to move the origin\n",
    "* If the vector $x$ goes to $x'$, then $2x$ must go to $2x'$. In general cx must go to cx', since $A(cx) = c(Ax)$.\n",
    "* If the vectors $x$ and $y$ go to $x'$ and $y'$, then their sum $x+y$ must go to $x' + y'$ -- since $A(x+y) = Ax + Ay$.\n",
    "\n",
    "\n",
    "Transformation that obey 3 rules above are called **linear transformations**.\n",
    "\n",
    "\n",
    "## Transformations represented by Matrices\n",
    "\n",
    "Linearity has a crucial consequence: **If we know $Ax$ for each vector in a basis, then we know $Ax$ for each vector in the entire space**.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
