---
title: "Algae-Casestudies"
author: "Habui"
date: "Thursday, October 08, 2015"
output: html_document
---

# Step 0: Prepare for analysis
```{r}
library('DMwR')
library('cluster')
library('rpart')
data(algae)
```


# Step 1: Examine the dataset

The idea is to calculate the missing value based on values of similar rows. Similar could be calculated in several metrics; the most familar, well-known is Euclidean. 


```{r}
summary(algae)
```

A picture worths a thoundsand words. Besides, `summary`, we could plot the dataset to observer its distributions. For example, the plot of `mxPH` could be obtained by:

```{r}
hist(algae$mxPH, prob=T, xlab='', main='Histogram of mxPH', ylim=0:1)
lines(density(algae$mxPH, na.rm=T))
rug(jitter(algae$mxPH))
```

# Step 2: Clean up the data. Process unknown values

## 1. Removing observations with too many unknown values

```{r}
# Remove rows with too many NAs
algae <- algae[-c(62, 199),]
```

## 2. Filling the unknowns with the most frequent values

```{r}
algae[48, 'mxPH'] <- mean(algae$mxPH, na.rm=T)
```

Though, this method is sometime dangerous, and should be done in cautious. For example, the distribution is skewed to higher values, and there are few extreme values that make the mean value highly unrepresentative of the most frequent value. 

```{r}
# Unlikely reasonable
algae[is.na(algae$Chla), 'Chla'] <- mean(algae$Chla, na.rm=T)

```

## 3. Filling the unknowns by exploring correlations

We could find the correlation between variables using function `cor`

```{r}
symnum(cor(algae[,4:18], use='complete.obs'))
```

We exclude three first column because they are normial. The use of `use='complete.obs'` tell R to obmit `NAs` from the calculation of correlation. 

We can observe that the correlations are most of the time irrelevant. However there are 2 exceptions: NH4 and NO3 and oPO4 and PO4. 

We could use linear regression to fill the correlation

```{r}
lm(oPO4 ~ PO4, data=algae)
fillPO4 <- function(o) {
  if (is.na(o)) return(NA)
  return((o+15.6142)/0.6466)
}

algae[is.na(algae$Chla), 'Chla'] <- median(algae$Chla,na.rm=T)
algae[is.na(algae$PO4), 'PO4'] <- sapply(algae[is.na(algae$PO4), 'oPO4'], fillPO4)

```


## 4. Filling the unknowns by exploring similarities between cases.

```{r}
algae <- algae[-c(62, 199),]
central.value <- function(x) {
  if (is.numeric(x)) median(x, na.rm=T)
  else if(is.factor(x)) levels(x)[which.max(table(x))]
  else {
    f <- as.factor(x)
    levels(f)[which.max(table(f))]
  }
}


dist.mtx <- as.matrix(daisy(algae,stand=T))
for(r in which(!complete.cases(algae))) {
  algae[r, which(is.na(algae[r,]))] <- 
    apply(data.frame(algae[c(as.integer(names(sort(dist.mtx[r,])[2:11]))),
                     which(is.na(algae[r,]))]), 
          2, central.value)
}

# Save the clean data at clean.algae
clean.algae <- algae
data(algae)
```


# Step 3: Prediction models

we will explore 2 preditive models that can be applied in algae domain:
* Linear Regression
* Regression Tree

## Multiple linear regression

We could obtain linear regression model using function `lm`

```{r}
lm.a1 = lm(a1 ~ ., data = clean.algae[,1:12])
summary(lm.a1)
```


R handles normial variables by creating a set of auxiliary variables. Namely for each factors with k levels, R create k-1 auxiliary variables. The variables have the values 0 or 1. A value of 1 means the associated value of the factor is "present", and that will mean that other auxiliary variables have value 0. 

**summary** function gives some **diagnostic information** including:
* The residuals of the fit of the linear model and the used data.
* For each coefficients, R will show its value and standard errors, as well as the importance of each coefficient. 
* Proportion of explained variance. 
* F-statistic

We should spend time here explaining a little bit the meaning of "The importance of each coefficient". The importance of a variable represents its influences on the final result. It is measured by "the null hypothesis", which test the valid of the statement: `H0: a variable is null`. In order to accept or reject the hypothesis, we conduct a t-student test.

## Regression Trees

We can obtain regression tree using the following commands:

```{r}
library(rpart)
data(algae)
algae <- algae[-c(62, 199),]
rt.a1 <- rpart(a1 ~ ., data = algae[,1:12])
```

The function `rpart` stop growing the trees when certain criteria are met
* The decrease in the deviance goes below a certain threshold
* The number of samples in the node is less than another threshold
* The tree depth exceeds another value.

The thresholds are controlled by the parameters: *cp*, *minsplit*, *maxdepth*. Their default values are 0.01, 20, and 30 respectively.

we should always check the validity of these default tree growth stopping criteria to prevent overfitting data. This can be carried out through a process of post-pruning of the obtained tree. The rpart package implements a pruning method named _cost complexity_ pruning. This method tries to estimate the value of _cp_ that ensues the best compromise between their predictive accuracy and tree size. 

Given a tree produced by *rpart()*, R can produced a set of sub-trees of this tree and estimate their predictive performance. This information can be obtained using the function *printcp()*.

```{r}
reliable.rpart <- function(form,data, se = 1,cp = 0,verbose=T, ...) {
  tree <- rpart(form, data, cp=cp, ...)
  if (verbose && ncol(tree$cptable) < 5) tree
  else {
    lin.min.err <- which.min(tree$cptable[, 4])
    if (verbose && lin.min.err == nrow(tree$cptable))
      warning("Minimal cross Validation Error is obtained with the largest tree\n. Further tree growth could produce more accurate tree\n")
    tol.err <- tree$cptable[lin.min.err, 4] + se * tree$cptable[lin.min.err, 5]
    se.lin <- which(tree$cptable[,4] <= tol.err)[1]
    prune.rpart(tree, cp=tree$cptable[se.lin, 1]+1e-9)
  }
}
```


# Step 4: Model evaluation and Selection

To obtain the prediction of any R model, one uses the function **predict()**. 

```{r}
lm.prediction.a1 <- predict(final.lm, data=clean.algae)
rt.prediction.a1 <- predict(rt.a1, data=algae)
```

Having a prediction, we can calculate their 

#### Mean Absolute Error:

```{r}
(mae.a1.lm <- mean(abs(lm.prediction.a1 - clean.algae[,'a1'])))
(mae.a1.rt <- mean(abs(rt.prediction.a1 - algae[,'a1'])))
```

#### Mean Squared Error
```{r}
(mse.a1.lm <- mean((lm.prediction.a1 - clean.algae[,'a1'])^2))
(mse.a1.rt <- mean((rt.prediction.a1 - algae[,'a1'])^2))
```

#### Normalized Mean Squared Error

```{r}
(nmse.a1.lm <- mean((lm.prediction.a1 - clean.algae[,'a1'])^2) / mean((mean(clean.algae[,'a1']) - clean.algae[,'a1'])^2))
(nmse.a1.rt <- mean((rt.prediction.a1 - algae[,'a1'])^2) / mean((mean(algae[,'a1']) - algae[,'a1'])^2))
```

The smaller NMSE, the better. 

#### Visual inspection of the prediction

The idea is to plot the whole prediction and obserse their result under the line with angle **pi/4**.

```{r}
old.par <- par(mfrow=c(2,1))
plot(lm.prediction.a1, clean.algae[, 'a1'], main="Linear model", xlab="Prediction", ylab="True Value")
abline(0, 1, lty=2)
plot(rt.prediction.a1, algae[, 'a1'], main="Regression Tree model", xlab="Prediction", ylab="True Value")
abline(0, 1, lty=2)
par(old.par)
```


Several criteria exists for evaluating models. Among the most popular are criteria that calculate the **predictive performance of models**. The predictive performances of models is obtained by comparing the prediction of models with the real values of the target variables. 

The key issue here is to obtain a reliable estimate of a model performance on data for which we do not know the true target value. The measures calculated using the training data are unreliable, because they are biased. In effect, there are models that can easily obtain zero prediction error on the training data, however, this performance will hardly generalize over new samples for which the target variable value is unknown. This phenomenon is usually known as _overfitting_. 

_K-fold Cross Validation_ is among the most frequently used methods of obtaining these reliable estimates for small data sets like our case study. The idea is: otain `K` equally sized and randomized sub-sets of training data. For each of these `K` subsets, build a model using the remaining K-1 sets and evaluate this model on the Kth subset. Store the performance of the model and repeat this process for all remaining subsets. In the end, we have K performance measures, all obtained by testing a model on data not used for its construction. The K-fold Cross Validation estimation is the average of these K measures. A common choice for K is 10.

The following code puts the ideas in practice for 2 models:
* linear regression
* decision tree

```{r, echo=FALSE}
cross.validation <- function(all.data, clean.data, n.folds = 10) {
  n <- nrow(all.data)
  idx <- sample(n, n)
  all.data <- all.data[idx,]
  clean.data <- clean.data[idx,]
  
  n.each.part <- as.integer(n/n.folds)
  
  perf.lm <- vector()
  perf.rt <- vector()
  
  for(i in 1:n.folds) {
    cat('Fold ', i, '\n')
    out.fold <- ((i - 1)*n.each.part+1):(i*n.each.part)
    
    l.model <- lm(a1 ~ ., clean.data[-out.fold, 1:12])
    l.model <- step(l.model)
    l.model.preds <- predict(l.model, clean.data[out.fold, 1:12])
    l.model.preds <- ifelse(l.model.preds < 0, 0, l.model.preds)
    
    r.model <- reliable.rpart(a1 ~ ., all.data[-out.fold, 1:12])
    r.model.preds <- predict(r.model, all.data[out.fold, 1:12])
    
    perf.lm[i] <- mean((l.model.preds - all.data[out.fold, 'a1'])^2) /
      mean((mean(all.data[- out.fold,'a1']) - all.data[out.fold,'a1'])^2)
    perf.rt[i] <- mean((r.model.preds - all.data[out.fold,'a1'])^2) /
      mean((mean(all.data[- out.fold,'a1']) - all.data[out.fold,'a1'])^2)
  }
  
  list(lm=list(avg=mean(perf.lm), std=sd(perf.lm), fold.res=perf.lm),
    rt=list(avg=mean(perf.rt), std=sd(perf.rt), fold.res=perf.rt))
}

cv10.res <- cross.validation(algae, clean.algae)

```

Regression tree has a slightly better score. However, we can see a large variation of the scores on the different folds, which is also captured by the large standard deviations of both methods. We can carry out a formal statistical test to check whether the difference between the two means is statistically significant with some degree of confidence. We can use **t-statistics** to test the hypothesis that: the difference between two means of methods is zero. 

```{r}
t.test(cv10.res$lm$fold.res, cv10.res$rt$fold.res, paired=T)
```

**p-value** is above the value of **0.o5**. mean of the difference is **-0.05** which means the regression tree models have larger mean. However, we have no reasons to prefer a model over the other.

# Predictions for the 7 algae

```{r}
data4dist <- rbind(algae[,1:11], test.algae[,1:11])
dist.mtx <- as.matrix(daisy(data4dist, stand=T))
clean.test.algae <- test.algae
for (r in which(!complete.cases(test.algae))) {
  clean.test.algae[r, which(is.na(test.algae[r,]))] <-
    apply(data.frame(data4dist[c(as.integer(names(sort(dist.mtx[r+198,])[2:11]))), which(is.na(test.algae[r,]))]), 2, central.value)
}
```

```{r}
cv.all <- function(all.data, clean.data, n.folds=10) {
  n <- nrow(all.data)
  idx <- sample(n, n)
  all.data <- all.data[idx,]
  clean.data <- clean.data[idx,]
  
  n.each.part <- as.integer(n/n.folds)
  perf.lm <- matrix(nrow=n.folds, ncol=7)
  perf.rt <- matrix(nrow=n.folds, ncol=7)
  perf.comb <- matrix(nrow=n.folds, ncol=7)
  
  for(i in 1:n.folds) {
    cat('Fold ', i, '\n')
    out.fold <- ((i-1)*n.each.part+1):(i*n.each.part)
    
    for(a in 1:7) {
      form <- as.formula(paste(names(all.data)[11+a], "~."))
      l.model <- lm(form, clean.data[-out.fold, c(1:11, 11+a)])
      l.model <- step(l.model)
      l.model.preds <- predict(l.model clean.data[out.fold, c(1:11, 11+a)])
      l.model.preds <- ifelse(l.model.preds < 0, 0, l.model.preds)
      
      r.model <- reliable.rpart(form, all.data[-out.fold, c(1:11, 11+a)])
      r.model.preds <- predict(r.model, all.data[out.fold, c(1:11, 11+a)])
      
      perf.lm[i, a] <- mean((l.model.preds - all.data[out.fold, 11+a])^2) /
        mean((mean(all.data[-out.fold, 11+a]) - all.data[out.fold, 11+a])^2)
      perf.rt[i, a] <- mean((r.model.preds - all.data[out.fold, 11+a])^2) /
        mean((mean(all.data[-out.fold, 11+a]) - all.data[out.fold, 11+a])^2)      
      
      w1 <- 1-perf.lm[i,a]/(perf.lm[i, a]+perf.rt[i,a])
      wr <- 1 - w1
      comb.preds <- w1*l.model.preds + wr*r.model.preds
      perf.comb[i,a] <- mean((comb.preds - all.data[out.fold, 11+a])^2) / 
        mean((mean(all.data[-out.fold, 11+a]) - all.data[out.fold, 11+a])^2)
      
      cat(paste("Algal a",a, sep=""), 
          "\tlm=", perf.lm[i,a], 
          "\trt=", perf.rt[i,a], "\tcomb=", perf.comb[i,a], "\n")
    }
    
  }
}
```

